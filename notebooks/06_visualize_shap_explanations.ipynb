{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-07T21:04:23.021975Z",
     "start_time": "2025-07-07T21:04:14.577120Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import os\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "import numpy as np\n",
    "import shap\n",
    "import torch"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T21:04:26.738321Z",
     "start_time": "2025-07-07T21:04:23.021975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Load tokenizer and fine-tuned classifier weights\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-cased\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)\n",
    "model.load_state_dict(torch.load(\"../outputs/model/bert_toxic_classifier.pt\", map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Wrapper so SHAP can call the model with raw texts\n",
    "class WrappedModel:\n",
    "    def __init__(self, model, tokenizer, device):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, texts):\n",
    "        if isinstance(texts, str):\n",
    "            texts = [texts]\n",
    "        elif isinstance(texts, (pd.Series, np.ndarray)):\n",
    "            texts = texts.tolist()\n",
    "        enc = self.tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "        enc = {k: v.to(self.device) for k, v in enc.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**enc)\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        return probs[:, 1].detach().cpu().numpy()\n",
    "\n",
    "# SHAP explainer using the same tokenizer (Text masker)\n",
    "explainer = shap.Explainer(WrappedModel(model, tokenizer, device), shap.maskers.Text(tokenizer))"
   ],
   "id": "bc25c88cc19ba860",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŸ¢ Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T21:04:27.353579Z",
     "start_time": "2025-07-07T21:04:26.738321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load Toxic Spans data and align indices to SHAP results\n",
    "df_orig = pd.read_csv(\"../data/toxic_spans.csv\")\n",
    "df_orig[\"position\"] = df_orig[\"position\"].apply(ast.literal_eval)\n",
    "df_orig[\"text_of_post\"] = df_orig[\"text_of_post\"].astype(str).apply(lambda x: x.strip())\n",
    "df_orig = df_orig[df_orig[\"text_of_post\"] != \"\"].reset_index(drop=True)\n",
    "\n",
    "# Load per-sample SHAP metrics and attach gold spans by original index\n",
    "df_results = pd.read_csv(\"../outputs/shap/evaluation_metrics.csv\")\n",
    "df_results[\"true_spans\"] = df_results[\"index\"].apply(lambda idx: df_orig.loc[idx, \"position\"])"
   ],
   "id": "a52c82f02f022cdd",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T21:04:27.369022Z",
     "start_time": "2025-07-07T21:04:27.353579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# goldnpred = gold, gold only = lightgreen, pred only = lightcoral\n",
    "def mark_spans_combined(text, true_spans, pred_spans):\n",
    "    html = \"\"\n",
    "    for i, c in enumerate(text):\n",
    "        if i in true_spans and i in pred_spans:\n",
    "            html += f'<span style=\"background-color:gold;\">{c}</span>'\n",
    "        elif i in true_spans:\n",
    "            html += f'<span style=\"background-color:lightgreen;\">{c}</span>'\n",
    "        elif i in pred_spans:\n",
    "            html += f'<span style=\"background-color:lightcoral;\">{c}</span>'\n",
    "        else:\n",
    "            html += c\n",
    "    return html\n"
   ],
   "id": "a70202cb91c69a23",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T21:06:07.118908Z",
     "start_time": "2025-07-07T21:06:07.106963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Take top-N examples by SHA F1 and write combined HTML overlays\n",
    "top_n = 10\n",
    "samples = df_results.sort_values(\"f1\", ascending=False).head(top_n)\n",
    "\n",
    "os.makedirs(\"../outputs/figures\", exist_ok=True)\n",
    "with open(\"../outputs/figures/shap_top_samples.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for i, row in samples.iterrows():\n",
    "        text = row[\"text\"]\n",
    "        pred_spans = set()\n",
    "        true_spans = set(ast.literal_eval(str(row[\"true_spans\"])))\n",
    "        tokens = ast.literal_eval(row[\"tokens\"])\n",
    "        # 'scores' saved as string; parse to numpy array\n",
    "        scores = np.fromstring(row[\"scores\"].strip(\"[]\"), sep=\" \")\n",
    "\n",
    "        # Project token-level scores back to character offsets\n",
    "        enc = tokenizer(text, return_offsets_mapping=True, truncation=True, padding=\"max_length\", max_length=128)\n",
    "        offsets = enc[\"offset_mapping\"]\n",
    "\n",
    "        # Threshold SHAP values to choose \"toxic-driving\" tokens\n",
    "        threshold = 0.5\n",
    "        for j, (start, end) in enumerate(offsets):\n",
    "            if start == end or j >= len(scores):\n",
    "                continue\n",
    "            if scores[j] >= threshold:\n",
    "                pred_spans.update(range(start, end))\n",
    "\n",
    "        html = mark_spans_combined(text, true_spans, pred_spans)\n",
    "        f.write(f\"\"\"\n",
    "        <h4>Sample {int(row['index'])}</h4>\n",
    "        <p><strong>F1:</strong> {row['f1']:.2f}, <strong>Precision:</strong> {row['precision']:.2f}, <strong>Recall:</strong> {row['recall']:.2f}</p>\n",
    "        <pre style='font-size: 15px; line-height: 1.5; white-space: pre-wrap'>{html}</pre>\n",
    "        <hr>\n",
    "        \"\"\")\n",
    "\n",
    "print(\"Saved HTML visualizations: ../outputs/figures/shap_top_samples.html\")\n"
   ],
   "id": "3824c70e618664fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved HTML visualizations: ../outputs/figures/shap_top_samples.html\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T21:06:43.949298Z",
     "start_time": "2025-07-07T21:06:40.150133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save SHAP's native text plots for a couple of top samples\n",
    "for i, row in samples.head(2).iterrows():\n",
    "    text = row[\"text\"]\n",
    "    shap_values = explainer([text])\n",
    "    try:\n",
    "        shap_html = shap.plots.text(shap_values[0], display=False)\n",
    "        with open(f\"../outputs/figures/shap_explanation_{i}.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(shap_html)\n",
    "        print(f\"Saved SHAP explanation HTML for sample {i}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save SHAP plot for {i}: {e}\")\n"
   ],
   "id": "2550288ba71e7d6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved SHAP explanation HTML for sample 2502\n",
      "âœ… Saved SHAP explanation HTML for sample 6939\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T21:07:05.065392Z",
     "start_time": "2025-07-07T21:07:05.034143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Export the metadata for the selected top-N samples\n",
    "samples.to_csv(\"../outputs/figures/shap_top_samples.csv\", index=False)\n",
    "print(\"Saved top sample data: ../outputs/figures/shap_top_samples.csv\")"
   ],
   "id": "4c0737724b5b851d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved top sample data: ../outputs/figures/shap_top_samples.csv\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (thesis-toxic)",
   "language": "python",
   "name": "thesis-toxic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
